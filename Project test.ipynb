{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "44d7d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1577e341",
   "metadata": {},
   "source": [
    "# Create custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "c2017524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform = None, target_transform = None):        \n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):        \n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):        \n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]       \n",
    "        if self.transform:\n",
    "            image = self.transform(image)           \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf2587",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "1f93cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file = 'train_labels.csv'\n",
    "img_dir_train = 'train_set/train_set'\n",
    "img_dir_test = 'test_set/test_set'\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    transforms.Resize((28, 28))\n",
    "])\n",
    "\n",
    "dataset = CustomImageDataset(annotations_file, img_dir_train, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9288a",
   "metadata": {},
   "source": [
    "# Display image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "10d5ec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 3, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 8\n"
     ]
    }
   ],
   "source": [
    "# load images as PIL\n",
    "train_dataloader = DataLoader(dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "# only works when the transform ToTensor() is not applied\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "# don't really know what permute does, but it works\n",
    "img = train_features[0].squeeze().permute(1, 2, 0)\n",
    "label = train_labels[0]\n",
    "\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be500c",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "765996b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set into train and validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_subset, val_subset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size], generator = torch.Generator().manual_seed(1))\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_subset, batch_size = batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_subset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "b786a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# cuda or cpu\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4e649",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "9f995183",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2352, 1800),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1800, 1500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1500, 1200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1200, 800),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(800, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 81),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "40c68b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X.float()) # only works when X is a float\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() # update parameters / weights\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss: > 7f}  [{current: > 5d} / {size: > 5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.float()) # only works when X is a float\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100 * correct): > 0.1f}%, Avg loss: {test_loss: > 8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e783e",
   "metadata": {},
   "source": [
    "# How well does the model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "7892b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.383621  [    0/24489]\n",
      "loss: 4.383384  [ 6400/24489]\n",
      "loss: 4.419337  [12800/24489]\n",
      "loss: 4.387862  [19200/24489]\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 4.379148 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.389859  [    0/24489]\n",
      "loss: 4.380431  [ 6400/24489]\n",
      "loss: 4.390921  [12800/24489]\n",
      "loss: 4.377818  [19200/24489]\n",
      "Test Error: \n",
      " Accuracy: 1.9%, Avg loss: 4.366914 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.331046  [    0/24489]\n",
      "loss: 4.376426  [ 6400/24489]\n",
      "loss: 4.388202  [12800/24489]\n",
      "loss: 4.331815  [19200/24489]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 4.350410 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.347972  [    0/24489]\n",
      "loss: 4.294960  [ 6400/24489]\n",
      "loss: 4.375929  [12800/24489]\n",
      "loss: 4.280212  [19200/24489]\n",
      "Test Error: \n",
      " Accuracy: 2.9%, Avg loss: 4.330817 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.255974  [    0/24489]\n",
      "loss: 4.236732  [ 6400/24489]\n",
      "loss: 4.304360  [12800/24489]\n",
      "loss: 4.272893  [19200/24489]\n",
      "Test Error: \n",
      " Accuracy: 2.9%, Avg loss: 4.311945 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1} \\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21654d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d067e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
